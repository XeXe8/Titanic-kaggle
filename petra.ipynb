{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   Pclass  Sex  Age  Fare  Embarked  Title  IsAlone  Age*Class\n",
       " 0       3    0    0     0         0      1        0          0\n",
       " 1       1    1    0     3         1      3        0          0\n",
       " 2       3    1    0     1         0      2        1          0\n",
       " 3       1    1    0     3         0      3        0          0\n",
       " 4       3    0    0     1         0      1        1          0,\n",
       " (891,),\n",
       " (418, 8))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, make_scorer\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "# Load the train.csv data\n",
    "train_data = pd.read_csv(r\"train.csv\")\n",
    "test_data = pd.read_csv(r\"test.csv\")\n",
    "\n",
    "train_data = train_data.drop(['Ticket', 'Cabin'], axis=1)\n",
    "test_data = test_data.drop(['Ticket', 'Cabin'], axis=1)\n",
    "combine = [train_data, test_data]\n",
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n",
    " \t'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "\n",
    "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset['Title'].map(title_mapping)\n",
    "    dataset['Title'] = dataset['Title'].fillna(0)\n",
    "for dataset in combine:\n",
    "    dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\n",
    "\n",
    "train_data.head()\n",
    "train_data = train_data.drop(['Name', 'PassengerId'], axis=1)\n",
    "test_data = test_data.drop(['Name'], axis=1)\n",
    "combine = [train_data, test_data]\n",
    "train_data.shape, test_data.shape\n",
    "guess_ages = np.zeros((2,3))\n",
    "guess_ages\n",
    "train_data['AgeBand'] = pd.cut(train_data['Age'], 5)\n",
    "for dataset in combine:    \n",
    "    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0\n",
    "    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n",
    "    dataset.loc[ dataset['Age'] > 64, 'Age']\n",
    "train_data.head()\n",
    "for dataset in combine:\n",
    "    for i in range(0, 2):\n",
    "        for j in range(0, 3):\n",
    "            guess_df = dataset[(dataset['Sex'] == i) & \\\n",
    "                                  (dataset['Pclass'] == j+1)]['Age'].dropna()\n",
    "\n",
    "            # age_mean = guess_df.mean()\n",
    "            # age_std = guess_df.std()\n",
    "            # age_guess = rnd.uniform(age_mean - age_std, age_mean + age_std)\n",
    "\n",
    "            age_guess = guess_df.median()\n",
    "\n",
    "            # Convert random age float to nearest .5 age\n",
    "            guess_ages[i,j] = int( age_guess/0.5 + 0.5 ) * 0.5\n",
    "            \n",
    "    for i in range(0, 2):\n",
    "        for j in range(0, 3):\n",
    "            dataset.loc[ (dataset.Age.isnull()) & (dataset.Sex == i) & (dataset.Pclass == j+1),\\\n",
    "                    'Age'] = guess_ages[i,j]\n",
    "\n",
    "    dataset['Age'] = dataset['Age'].astype(int)\n",
    "\n",
    "train_data.head()\n",
    "train_data['AgeBand'] = pd.cut(train_data['Age'], 5)\n",
    "for dataset in combine:    \n",
    "    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0\n",
    "    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n",
    "    dataset.loc[ dataset['Age'] > 64, 'Age']\n",
    "train_data.head()\n",
    "train_data = train_data.drop(['AgeBand'], axis=1)\n",
    "combine = [train_data, test_data]\n",
    "train_data.head()\n",
    "for dataset in combine:\n",
    "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "\n",
    "train_data[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n",
    "for dataset in combine:\n",
    "    dataset['IsAlone'] = 0\n",
    "    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "\n",
    "train_data[['IsAlone', 'Survived']].groupby(['IsAlone'], as_index=False).mean()\n",
    "train_data = train_data.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\n",
    "test_data = test_data.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\n",
    "combine = [train_data, test_data]\n",
    "\n",
    "train_data.head()\n",
    "for dataset in combine:\n",
    "    dataset['Age*Class'] = dataset.Age * dataset.Pclass\n",
    "\n",
    "train_data.loc[:, ['Age*Class', 'Age', 'Pclass']].head(10)\n",
    "freq_port = train_data.Embarked.dropna().mode()[0]\n",
    "freq_port\n",
    "for dataset in combine:\n",
    "    dataset['Embarked'] = dataset['Embarked'].fillna(freq_port)\n",
    "for dataset in combine:\n",
    "    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n",
    "test_data['Fare'].fillna(test_data['Fare'].dropna().median(), inplace=True)\n",
    "test_data.head()\n",
    "train_data['FareBand'] = pd.qcut(train_data['Fare'], 4)\n",
    "for dataset in combine:\n",
    "    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n",
    "    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n",
    "    dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n",
    "    dataset['Fare'] = dataset['Fare'].astype(int)\n",
    "\n",
    "train_data = train_data.drop(['FareBand'], axis=1)\n",
    "combine = [train_data, test_data]\n",
    "    \n",
    "train_data.head(10)\n",
    "\n",
    "# Separate features and target variable\n",
    "X_train = train_data.drop(\"Survived\", axis=1)\n",
    "Y_train = train_data[\"Survived\"]\n",
    "X_test  = test_data.drop(\"PassengerId\", axis=1).copy()\n",
    "X_train.head(), Y_train.shape, X_test.shape\n",
    "# Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\PythonIlmuData1\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\PythonIlmuData1\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\PythonIlmuData1\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Classifier  Accuracy  Precision    Recall        F1\n",
      "0     Statistik - Logistic Regression  0.781150   0.722434  0.694545  0.708138\n",
      "1             Statistik - Naive Bayes  0.660925   0.557393  0.909082  0.683285\n",
      "2                      Geometri - KNN  0.805831   0.789194  0.667554  0.721211\n",
      "3               Geometri - Linear SVM  0.786762   0.739372  0.679792  0.707965\n",
      "4         Geometri - SVM (RBF kernel)  0.781144   0.704104  0.743309  0.721682\n",
      "5   Neurosains - MLP (1 hidden layer)  0.809240   0.790978  0.668335  0.736514\n",
      "6  Neurosains - MLP (2 hidden layers)  0.818178   0.795474  0.685746  0.743797\n",
      "7              Logika - Decision Tree  0.801356   0.792650  0.652664  0.710121\n",
      "8              Sosial - Random Forest  0.809227   0.779800  0.699807  0.720072\n",
      "9          Sosial - Gradient Boosting  0.814826   0.822474  0.661437  0.729095\n"
     ]
    }
   ],
   "source": [
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, Y_train)\n",
    "Y_pred = logreg.predict(X_test)\n",
    "acc_log = round(logreg.score(X_train, Y_train) * 100, 2)\n",
    "acc_log\n",
    "#Corr \n",
    "coeff_df = pd.DataFrame(train_data.columns.delete(0))\n",
    "coeff_df.columns = ['Feature']\n",
    "coeff_df[\"Correlation\"] = pd.Series(logreg.coef_[0])\n",
    "\n",
    "coeff_df.sort_values(by='Correlation', ascending=False)\n",
    "# Initialize classifiers for each paradigm\n",
    "classifiers = {\n",
    "    'Statistik - Logistic Regression': LogisticRegression(),\n",
    "    'Statistik - Naive Bayes': GaussianNB(),\n",
    "    'Geometri - KNN': KNeighborsClassifier(),\n",
    "    'Geometri - Linear SVM': SVC(kernel='linear'),\n",
    "    'Geometri - SVM (RBF kernel)': SVC(kernel='rbf'),\n",
    "    'Neurosains - MLP (1 hidden layer)': MLPClassifier(hidden_layer_sizes=(100,), max_iter=500),\n",
    "    'Neurosains - MLP (2 hidden layers)': MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=500),\n",
    "    'Logika - Decision Tree': DecisionTreeClassifier(),\n",
    "    'Sosial - Random Forest': RandomForestClassifier(),\n",
    "    'Sosial - Gradient Boosting': GradientBoostingClassifier()\n",
    "}\n",
    "\n",
    "# Define evaluation metrics\n",
    "metrics = {\n",
    "    'Accuracy': make_scorer(accuracy_score),\n",
    "    'Precision': make_scorer(precision_score),\n",
    "    'Recall': make_scorer(recall_score),\n",
    "    'F1': make_scorer(f1_score)\n",
    "}\n",
    "\n",
    "# Perform 5-fold cross validation for each classifier and calculate performance metrics\n",
    "results = []\n",
    "for name, clf in classifiers.items():\n",
    "    fold_results = {'Classifier': name}\n",
    "    for metric_name, scorer in metrics.items():\n",
    "        scores = cross_val_score(clf, X_train, Y_train, cv=KFold(n_splits=5, shuffle=True, random_state=42), scoring=scorer)\n",
    "        fold_results[metric_name] = scores.mean()\n",
    "    results.append(fold_results)\n",
    "\n",
    "# Create a DataFrame to display results\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display results\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Statistik - Logistic Regression</td>\n",
       "      <td>0.781150</td>\n",
       "      <td>0.722434</td>\n",
       "      <td>0.694545</td>\n",
       "      <td>0.708138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Statistik - Naive Bayes</td>\n",
       "      <td>0.660925</td>\n",
       "      <td>0.557393</td>\n",
       "      <td>0.909082</td>\n",
       "      <td>0.683285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Geometri - KNN</td>\n",
       "      <td>0.805831</td>\n",
       "      <td>0.789194</td>\n",
       "      <td>0.667554</td>\n",
       "      <td>0.721211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Geometri - Linear SVM</td>\n",
       "      <td>0.786762</td>\n",
       "      <td>0.739372</td>\n",
       "      <td>0.679792</td>\n",
       "      <td>0.707965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Geometri - SVM (RBF kernel)</td>\n",
       "      <td>0.781144</td>\n",
       "      <td>0.704104</td>\n",
       "      <td>0.743309</td>\n",
       "      <td>0.721682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Neurosains - MLP (1 hidden layer)</td>\n",
       "      <td>0.809240</td>\n",
       "      <td>0.790978</td>\n",
       "      <td>0.668335</td>\n",
       "      <td>0.736514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Neurosains - MLP (2 hidden layers)</td>\n",
       "      <td>0.818178</td>\n",
       "      <td>0.795474</td>\n",
       "      <td>0.685746</td>\n",
       "      <td>0.743797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Logika - Decision Tree</td>\n",
       "      <td>0.801356</td>\n",
       "      <td>0.792650</td>\n",
       "      <td>0.652664</td>\n",
       "      <td>0.710121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sosial - Random Forest</td>\n",
       "      <td>0.809227</td>\n",
       "      <td>0.779800</td>\n",
       "      <td>0.699807</td>\n",
       "      <td>0.720072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sosial - Gradient Boosting</td>\n",
       "      <td>0.814826</td>\n",
       "      <td>0.822474</td>\n",
       "      <td>0.661437</td>\n",
       "      <td>0.729095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Classifier  Accuracy  Precision    Recall        F1\n",
       "0     Statistik - Logistic Regression  0.781150   0.722434  0.694545  0.708138\n",
       "1             Statistik - Naive Bayes  0.660925   0.557393  0.909082  0.683285\n",
       "2                      Geometri - KNN  0.805831   0.789194  0.667554  0.721211\n",
       "3               Geometri - Linear SVM  0.786762   0.739372  0.679792  0.707965\n",
       "4         Geometri - SVM (RBF kernel)  0.781144   0.704104  0.743309  0.721682\n",
       "5   Neurosains - MLP (1 hidden layer)  0.809240   0.790978  0.668335  0.736514\n",
       "6  Neurosains - MLP (2 hidden layers)  0.818178   0.795474  0.685746  0.743797\n",
       "7              Logika - Decision Tree  0.801356   0.792650  0.652664  0.710121\n",
       "8              Sosial - Random Forest  0.809227   0.779800  0.699807  0.720072\n",
       "9          Sosial - Gradient Boosting  0.814826   0.822474  0.661437  0.729095"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.13 ('PythonIlmuData1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9111e1d3aae2699dc46d408508c057f8ebadbec093f8a01e0df102a5d66306e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
